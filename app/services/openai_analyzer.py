"""
OpenAI API ã‚’ä½¿ç”¨ã—ãŸæ¯’æ€§æ¤œçŸ¥ã‚µãƒ¼ãƒ“ã‚¹
GPT-4o-miniã¾ãŸã¯GPT-3.5-turboã‚’ä½¿ç”¨ã—ã¦é«˜ç²¾åº¦ãªæ—¥æœ¬èªæ¯’æ€§åˆ¤å®šã‚’å®Ÿè¡Œ
"""

import os
import json
import time
import asyncio
from typing import Dict, List, Tuple, Optional
from datetime import datetime
import openai
from openai import OpenAI
from dotenv import load_dotenv
import concurrent.futures
import logging

# ãƒ­ã‚¬ãƒ¼ã®è¨­å®š
logger = logging.getLogger(__name__)

# ã‚¹ã‚­ãƒ¼ãƒã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from app.models.schemas import ToxicityCategory

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()


class OpenAIAnalyzer:
    """OpenAI APIã‚’ä½¿ç”¨ã—ãŸæ¯’æ€§åˆ†æã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        """åˆæœŸåŒ–å‡¦ç†"""
        # APIã‚­ãƒ¼ã®è¨­å®š
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("OPENAI_API_KEY environment variable is not set")
        
        # OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
        self.client = OpenAI(api_key=api_key)
        
        # ãƒ¢ãƒ‡ãƒ«è¨­å®šï¼ˆã‚³ã‚¹ãƒˆåŠ¹ç‡ã‚’è€ƒæ…®ã—ã¦gpt-4o-miniã‚’ä½¿ç”¨ï¼‰
        self.model = "gpt-4o-mini"  # ã¾ãŸã¯ "gpt-3.5-turbo"
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®åˆæœŸåŒ–
        self.cache = {}
        self.max_cache_size = 100
        
        # ã‚«ãƒ†ã‚´ãƒªå®šç¾©
        self.categories = {
            "severe_toxicity": "é‡åº¦ã®æ¯’æ€§ï¼ˆæ­»ã­ã€æ®ºã™ç­‰ï¼‰",
            "hate_speech": "ãƒ˜ã‚¤ãƒˆã‚¹ãƒ”ãƒ¼ãƒï¼ˆå·®åˆ¥çš„ç™ºè¨€ï¼‰",
            "violence": "æš´åŠ›çš„è¡¨ç¾",
            "sexual": "æ€§çš„ãªå†…å®¹",
            "discrimination": "å·®åˆ¥çš„è¡¨ç¾",
            "mild_toxicity": "è»½åº¦ã®æ¯’æ€§ï¼ˆãƒã‚«ã€ã‚¢ãƒ›ç­‰ï¼‰"
        }
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
        self.system_prompt = """ã‚ãªãŸã¯æ—¥æœ¬èªã®æ¯’æ€§æ¤œçŸ¥ã®å°‚é–€å®¶ã§ã™ã€‚
ä¸ãˆã‚‰ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†æã—ã€ä»¥ä¸‹ã®å½¢å¼ã§JSONã‚’è¿”ã—ã¦ãã ã•ã„ã€‚

{
    "toxicity_score": 0.0-1.0ã®æ•°å€¤ï¼ˆå…¨ä½“çš„ãªæ¯’æ€§ã‚¹ã‚³ã‚¢ï¼‰,
    "is_toxic": true/falseï¼ˆ0.3ä»¥ä¸Šã§æœ‰å®³ã¨åˆ¤å®šï¼‰,
    "confidence": 0.0-1.0ã®æ•°å€¤ï¼ˆåˆ¤å®šã®ç¢ºä¿¡åº¦ï¼‰,
    "categories": [
        {
            "name": "ã‚«ãƒ†ã‚´ãƒªå",
            "score": 0.0-1.0ã®æ•°å€¤,
            "detected": true/false,
            "keywords": ["æ¤œå‡ºã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰"]
        }
    ],
    "reasoning": "åˆ¤å®šç†ç”±ã®ç°¡æ½”ãªèª¬æ˜"
}

ã‚«ãƒ†ã‚´ãƒª:
- severe_toxicity: é‡åº¦ã®æ¯’æ€§ï¼ˆæ­»ã­ã€æ®ºã™ç­‰ï¼‰
- hate_speech: ãƒ˜ã‚¤ãƒˆã‚¹ãƒ”ãƒ¼ãƒï¼ˆãã‚‚ã„ã€ã‚¯ã‚ºç­‰ï¼‰
- violence: æš´åŠ›çš„è¡¨ç¾
- sexual: æ€§çš„ãªå†…å®¹
- discrimination: å·®åˆ¥çš„è¡¨ç¾
- mild_toxicity: è»½åº¦ã®æ¯’æ€§ï¼ˆãƒã‚«ã€ã‚¢ãƒ›ç­‰ï¼‰

é‡è¦ãªæ³¨æ„äº‹é …:
- æ–‡è„ˆã‚’è€ƒæ…®ã—ã¦åˆ¤å®šã™ã‚‹ã“ã¨
- æ•™è‚²çš„ãƒ»èª¬æ˜çš„ãªæ–‡è„ˆã§ã¯æ¯’æ€§ã‚’ä½ãè©•ä¾¡
- æ—¥æœ¬èªã®å¾®å¦™ãªãƒ‹ãƒ¥ã‚¢ãƒ³ã‚¹ã‚’ç†è§£ã™ã‚‹ã“ã¨
"""
    
    async def analyze_text(self, text: str) -> Dict:
        """
        ãƒ†ã‚­ã‚¹ãƒˆã®æ¯’æ€§ã‚’åˆ†æ
        
        Args:
            text: åˆ†æå¯¾è±¡ã®ãƒ†ã‚­ã‚¹ãƒˆ
            
        Returns:
            åˆ†æçµæœã®è¾æ›¸
        """
        start_time = time.time()
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
        if text in self.cache:
            cached_result = self.cache[text].copy()
            cached_result['cache_hit'] = True
            cached_result['processing_time'] = 0.001
            return cached_result
        
        try:
            # OpenAI APIã‚’å‘¼ã³å‡ºã—
            response = await asyncio.to_thread(
                self.client.chat.completions.create,
                model=self.model,
                messages=[
                    {"role": "system", "content": self.system_prompt},
                    {"role": "user", "content": f"ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã®æ¯’æ€§ã‚’åˆ†æã—ã¦ãã ã•ã„:\n\n{text}"}
                ],
                temperature=0.1,  # ä¸€è²«æ€§ã®ãŸã‚ä½ã‚ã«è¨­å®š
                max_tokens=500,
                response_format={"type": "json_object"}
            )
            
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®è§£æ
            result_text = response.choices[0].message.content
            result_data = json.loads(result_text)
            
            # çµæœã®æ§‹é€ åŒ–
            categories = []
            for cat_data in result_data.get('categories', []):
                if cat_data.get('detected', False):
                    category = ToxicityCategory(
                        name=cat_data['name'],
                        score=cat_data.get('score', 0.0),
                        keywords_found=cat_data.get('keywords', [])
                    )
                    categories.append({
                        'name': category.name,
                        'score': category.score,
                        'keywords_found': category.keywords_found
                    })
            
            # æœ€çµ‚çµæœã®æ§‹ç¯‰
            result = {
                'score': result_data.get('toxicity_score', 0.0),
                'is_toxic': result_data.get('is_toxic', False),
                'confidence': result_data.get('confidence', 0.5),
                'categories': categories,
                'model': self.model,
                'reasoning': result_data.get('reasoning', ''),
                'processing_time': time.time() - start_time,
                'cache_hit': False,
                'timestamp': datetime.now().isoformat()
            }
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
            if len(self.cache) >= self.max_cache_size:
                # æœ€ã‚‚å¤ã„ã‚¨ãƒ³ãƒˆãƒªã‚’å‰Šé™¤
                oldest_key = min(self.cache.keys(), 
                               key=lambda k: self.cache[k].get('timestamp', ''))
                del self.cache[oldest_key]
            
            self.cache[text] = result.copy()
            
            return result
            
        except Exception as e:
            print(f"OpenAI API error: {str(e)}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            return {
                'score': 0.0,
                'is_toxic': False,
                'confidence': 0.0,
                'categories': [],
                'model': self.model,
                'error': str(e),
                'processing_time': time.time() - start_time,
                'cache_hit': False,
                'timestamp': datetime.now().isoformat()
            }
    
    def analyze(self, text: str) -> Tuple[float, List[ToxicityCategory], float]:
        """åŒæœŸç‰ˆã®åˆ†æãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆMultiModelAnalyzeräº’æ›ï¼‰"""
        try:
            # æ—¢å­˜ã®ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã‚’ãƒã‚§ãƒƒã‚¯
            try:
                loop = asyncio.get_running_loop()
                # ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ãŒå®Ÿè¡Œä¸­ã®å ´åˆã€åˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ã§å®Ÿè¡Œ
                import concurrent.futures
                with concurrent.futures.ThreadPoolExecutor() as executor:
                    future = executor.submit(asyncio.run, self.analyze_text(text))
                    result = future.result()
            except RuntimeError:
                # ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ãŒå®Ÿè¡Œä¸­ã§ãªã„å ´åˆ
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                try:
                    result = loop.run_until_complete(self.analyze_text(text))
                finally:
                    loop.close()
            
            # çµæœã®å¤‰æ›
            score = result.get('score', 0.0)
            confidence = result.get('confidence', 0.5)
            
            # ã‚«ãƒ†ã‚´ãƒªã‚’å¤‰æ›
            categories = []
            for cat_detail in result.get('categories_detail', []):
                category = ToxicityCategory(
                    name=cat_detail['name'],
                    score=cat_detail['score'],
                    keywords_found=cat_detail.get('keywords', [])
                )
                categories.append(category)
            
            return score, categories, confidence
            
        except Exception as e:
            logger.error(f"OpenAIåˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")
            return 0.0, [], 0.0
    
    def get_model_info(self) -> Dict:
        """ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’å–å¾—"""
        return {
            'name': 'OpenAI',
            'model': self.model,
            'version': '1.0.0',
            'capabilities': [
                'é«˜ç²¾åº¦ãªæ–‡è„ˆç†è§£',
                'å¾®å¦™ãªãƒ‹ãƒ¥ã‚¢ãƒ³ã‚¹ã®æ¤œå‡º',
                'å¤šè¨€èªå¯¾å¿œï¼ˆæ—¥æœ¬èªæœ€é©åŒ–ï¼‰',
                'ã‚«ãƒ†ã‚´ãƒªåˆ¥è©³ç´°åˆ†æ'
            ],
            'cost_per_1k_tokens': {
                'gpt-4o-mini': {'input': 0.00015, 'output': 0.0006},
                'gpt-3.5-turbo': {'input': 0.0005, 'output': 0.0015}
            }
        }


# ãƒ†ã‚¹ãƒˆç”¨ã‚³ãƒ¼ãƒ‰
if __name__ == "__main__":
    import asyncio
    
    async def test_openai_analyzer():
        """OpenAIAnalyzerã®ãƒ†ã‚¹ãƒˆ"""
        print("=== OpenAI Analyzer Test ===")
        
        # ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼ã®åˆæœŸåŒ–
        try:
            analyzer = OpenAIAnalyzer()
            print(f"âœ… Initialized with model: {analyzer.model}")
        except ValueError as e:
            print(f"âŒ Initialization error: {e}")
            print("Please set OPENAI_API_KEY in .env file")
            return
        
        # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹
        test_cases = [
            "ã“ã‚“ã«ã¡ã¯ã€è‰¯ã„å¤©æ°—ã§ã™ã­",
            "ãƒã‚«ã˜ã‚ƒãªã„ã®",
            "æ­»ã­",
            "ã‚ãªãŸã¯ã‚¯ã‚ºã ",
            "ç´ æ™´ã‚‰ã—ã„ä¸€æ—¥ã‚’ãŠéã”ã—ãã ã•ã„"
        ]
        
        print("\n--- Testing analyze_text method ---")
        for text in test_cases:
            print(f"\nãƒ†ã‚­ã‚¹ãƒˆ: '{text}'")
            result = await analyzer.analyze_text(text)
            
            print(f"ã‚¹ã‚³ã‚¢: {result['score']:.3f}")
            print(f"æœ‰å®³åˆ¤å®š: {'ğŸš¨ æœ‰å®³' if result['is_toxic'] else 'âœ… å®‰å…¨'}")
            print(f"ä¿¡é ¼åº¦: {result['confidence']:.3f}")
            print(f"å‡¦ç†æ™‚é–“: {result['processing_time']:.3f}ç§’")
            
            if result.get('categories'):
                print("ã‚«ãƒ†ã‚´ãƒª:")
                for cat in result['categories']:
                    print(f"  - {cat['name']}: {cat['score']:.3f}")
            
            if result.get('reasoning'):
                print(f"ç†ç”±: {result['reasoning']}")
        
        print("\n--- Testing analyze method (sync) ---")
        # åŒæœŸãƒ¡ã‚½ãƒƒãƒ‰ã®ãƒ†ã‚¹ãƒˆã¯åˆ¥é€”å®Ÿè¡Œã™ã‚‹å¿…è¦ãŒã‚ã‚‹ãŸã‚ã€ã“ã“ã§ã¯ã‚¹ã‚­ãƒƒãƒ—
        print("æ³¨: analyzeãƒ¡ã‚½ãƒƒãƒ‰ã®ãƒ†ã‚¹ãƒˆã¯ã€éåŒæœŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå¤–ã§å®Ÿè¡Œã—ã¦ãã ã•ã„")
        
        # ãƒ¢ãƒ‡ãƒ«æƒ…å ±
        print("\n--- Model Info ---")
        info = analyzer.get_model_info()
        print(json.dumps(info, indent=2, ensure_ascii=False))
    
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    asyncio.run(test_openai_analyzer())