"""
Google Perspective API ã‚’ä½¿ç”¨ã—ãŸæ¯’æ€§æ¤œçŸ¥ã‚µãƒ¼ãƒ“ã‚¹
æ¯’æ€§æ¤œçŸ¥ã«ç‰¹åŒ–ã—ãŸGoogleã®APIã‚’ä½¿ç”¨ã—ã¦é«˜ç²¾åº¦ãªåˆ¤å®šã‚’å®Ÿè¡Œ
"""

import os
import time
import asyncio
from typing import Dict, List, Tuple, Optional
from datetime import datetime
from googleapiclient import discovery
from googleapiclient.errors import HttpError
from dotenv import load_dotenv
import json

# ã‚¹ã‚­ãƒ¼ãƒã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from app.models.schemas import ToxicityCategory

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()


class GoogleAnalyzer:
    """Google Perspective APIã‚’ä½¿ç”¨ã—ãŸæ¯’æ€§åˆ†æã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        """åˆæœŸåŒ–å‡¦ç†"""
        # APIã‚­ãƒ¼ã®è¨­å®š
        api_key = os.getenv("GOOGLE_API_KEY")
        if not api_key:
            raise ValueError("GOOGLE_API_KEY environment variable is not set")
        
        # Perspective APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
        self.client = discovery.build(
            "commentanalyzer",
            "v1alpha1",
            developerKey=api_key,
            discoveryServiceUrl="https://commentanalyzer.googleapis.com/$discovery/rest?version=v1alpha1",
            static_discovery=False,
        )
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®åˆæœŸåŒ–
        self.cache = {}
        self.max_cache_size = 100
        
        # åˆ†æã™ã‚‹å±æ€§ã®å®šç¾©
        self.attributes = {
            'TOXICITY': 'severe_toxicity',  # å…¨ä½“çš„ãªæ¯’æ€§
            'SEVERE_TOXICITY': 'severe_toxicity',  # é‡åº¦ã®æ¯’æ€§
            'IDENTITY_ATTACK': 'hate_speech',  # ã‚¢ã‚¤ãƒ‡ãƒ³ãƒ†ã‚£ãƒ†ã‚£æ”»æ’ƒ
            'INSULT': 'hate_speech',  # ä¾®è¾±
            'PROFANITY': 'mild_toxicity',  # ä¸é©åˆ‡ãªè¨€è‘‰
            'THREAT': 'violence',  # è„…è¿«
        }
        
        # ã‚«ãƒ†ã‚´ãƒªãƒãƒƒãƒ”ãƒ³ã‚°
        self.category_mapping = {
            'severe_toxicity': 'é‡åº¦ã®æ¯’æ€§',
            'hate_speech': 'ãƒ˜ã‚¤ãƒˆã‚¹ãƒ”ãƒ¼ãƒ',
            'violence': 'æš´åŠ›çš„è¡¨ç¾',
            'sexual': 'æ€§çš„ãªå†…å®¹',
            'discrimination': 'å·®åˆ¥çš„è¡¨ç¾',
            'mild_toxicity': 'è»½åº¦ã®æ¯’æ€§'
        }
    
    async def analyze_text(self, text: str) -> Dict:
        """
        ãƒ†ã‚­ã‚¹ãƒˆã®æ¯’æ€§ã‚’åˆ†æ
        
        Args:
            text: åˆ†æå¯¾è±¡ã®ãƒ†ã‚­ã‚¹ãƒˆ
            
        Returns:
            åˆ†æçµæœã®è¾æ›¸
        """
        start_time = time.time()
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
        if text in self.cache:
            cached_result = self.cache[text].copy()
            cached_result['cache_hit'] = True
            cached_result['processing_time'] = 0.001
            return cached_result
        
        try:
            # ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®æ§‹ç¯‰
            analyze_request = {
                'comment': {'text': text},
                'requestedAttributes': {
                    attr: {} for attr in self.attributes.keys()
                },
                'languages': ['ja'],  # æ—¥æœ¬èªã‚’æŒ‡å®š
                'doNotStore': True    # ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ä¿è­·
            }
            
            # Google Perspective APIã‚’å‘¼ã³å‡ºã—ï¼ˆéåŒæœŸï¼‰
            response = await asyncio.to_thread(
                self.client.comments().analyze(body=analyze_request).execute
            )
            
            # ã‚¹ã‚³ã‚¢ã®æŠ½å‡ºã¨å‡¦ç†
            scores = response.get('attributeScores', {})
            
            # ã‚«ãƒ†ã‚´ãƒªåˆ¥ã‚¹ã‚³ã‚¢ã®é›†è¨ˆ
            category_scores = {}
            max_score = 0.0
            
            for attr, category in self.attributes.items():
                if attr in scores:
                    score = scores[attr]['summaryScore']['value']
                    if category not in category_scores:
                        category_scores[category] = []
                    category_scores[category].append(score)
                    max_score = max(max_score, score)
            
            # ã‚«ãƒ†ã‚´ãƒªã®æ§‹ç¯‰
            categories = []
            detected_keywords = []  # Perspective APIã¯ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è¿”ã•ãªã„
            
            for category, score_list in category_scores.items():
                avg_score = sum(score_list) / len(score_list)
                if avg_score > 0.2:  # é–¾å€¤ä»¥ä¸Šã®ã‚«ãƒ†ã‚´ãƒªã®ã¿
                    category_obj = ToxicityCategory(
                        name=category,
                        score=avg_score,
                        keywords_found=[]  # Perspective APIã¯ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æä¾›ã—ãªã„
                    )
                    categories.append({
                        'name': category_obj.name,
                        'score': category_obj.score,
                        'keywords_found': category_obj.keywords_found
                    })
            
            # å…¨ä½“ã‚¹ã‚³ã‚¢ã®è¨ˆç®—ï¼ˆTOXICITYã‚¹ã‚³ã‚¢ã‚’å„ªå…ˆï¼‰
            overall_score = scores.get('TOXICITY', {}).get('summaryScore', {}).get('value', max_score)
            
            # ä¿¡é ¼åº¦ã®è¨ˆç®—ï¼ˆã‚¹ã‚³ã‚¢ã®åˆ†æ•£ã‚’åŸºã«ï¼‰
            if category_scores:
                all_scores = [s for scores in category_scores.values() for s in scores]
                score_variance = sum((s - overall_score) ** 2 for s in all_scores) / len(all_scores)
                confidence = max(0.5, min(1.0, 1.0 - score_variance))
            else:
                confidence = 0.5
            
            # æœ€çµ‚çµæœã®æ§‹ç¯‰
            result = {
                'score': overall_score,
                'is_toxic': overall_score >= 0.3,
                'confidence': confidence,
                'categories': categories,
                'model': 'perspective',
                'raw_scores': {attr: scores[attr]['summaryScore']['value'] 
                             for attr in scores if 'summaryScore' in scores[attr]},
                'processing_time': time.time() - start_time,
                'cache_hit': False,
                'timestamp': datetime.now().isoformat()
            }
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
            if len(self.cache) >= self.max_cache_size:
                # æœ€ã‚‚å¤ã„ã‚¨ãƒ³ãƒˆãƒªã‚’å‰Šé™¤
                oldest_key = min(self.cache.keys(), 
                               key=lambda k: self.cache[k].get('timestamp', ''))
                del self.cache[oldest_key]
            
            self.cache[text] = result.copy()
            
            return result
            
        except HttpError as e:
            error_content = json.loads(e.content.decode('utf-8')) if e.content else {}
            print(f"Perspective API error: {e.resp.status} - {error_content}")
            
            # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯å°‘ã—å¾…ã¤
            if e.resp.status == 429:
                await asyncio.sleep(1)
            
            # ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            return {
                'score': 0.0,
                'is_toxic': False,
                'confidence': 0.0,
                'categories': [],
                'model': 'perspective',
                'error': str(e),
                'processing_time': time.time() - start_time,
                'cache_hit': False,
                'timestamp': datetime.now().isoformat()
            }
        except Exception as e:
            print(f"Unexpected error: {str(e)}")
            return {
                'score': 0.0,
                'is_toxic': False,
                'confidence': 0.0,
                'categories': [],
                'model': 'perspective',
                'error': str(e),
                'processing_time': time.time() - start_time,
                'cache_hit': False,
                'timestamp': datetime.now().isoformat()
            }
    
    def analyze(self, text: str) -> Tuple[float, List[ToxicityCategory], float]:
        """
        MultiModelAnalyzeräº’æ›ã®analyzeãƒ¡ã‚½ãƒƒãƒ‰
        
        Args:
            text: åˆ†æå¯¾è±¡ã®ãƒ†ã‚­ã‚¹ãƒˆ
            
        Returns:
            (æ¯’æ€§ã‚¹ã‚³ã‚¢, ã‚«ãƒ†ã‚´ãƒªãƒªã‚¹ãƒˆ, ä¿¡é ¼åº¦)ã®ã‚¿ãƒ—ãƒ«
        """
        # éåŒæœŸãƒ¡ã‚½ãƒƒãƒ‰ã‚’åŒæœŸçš„ã«å®Ÿè¡Œ
        import asyncio
        
        # ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã®å–å¾—ã¾ãŸã¯ä½œæˆ
        try:
            loop = asyncio.get_event_loop()
        except RuntimeError:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
        
        # analyze_textã‚’å®Ÿè¡Œ
        result = loop.run_until_complete(self.analyze_text(text))
        
        # çµæœã®å¤‰æ›
        score = result.get('score', 0.0)
        confidence = result.get('confidence', 0.5)
        
        # ã‚«ãƒ†ã‚´ãƒªã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ä½œæˆ
        category_objects = []
        for cat_data in result.get('categories', []):
            category = ToxicityCategory(
                name=cat_data.get('name', ''),
                score=cat_data.get('score', 0.0),
                keywords_found=cat_data.get('keywords_found', [])
            )
            category_objects.append(category)
        
        return score, category_objects, confidence
    
    def get_model_info(self) -> Dict:
        """ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’å–å¾—"""
        return {
            'name': 'Google Perspective',
            'model': 'v1alpha1',
            'version': '1.0.0',
            'capabilities': [
                'æ¯’æ€§æ¤œçŸ¥ã«ç‰¹åŒ–',
                'å¤šè¨€èªå¯¾å¿œï¼ˆæ—¥æœ¬èªå«ã‚€ï¼‰',
                'è¤‡æ•°ã®æ¯’æ€§å±æ€§ã‚’åŒæ™‚åˆ†æ',
                'é«˜é€Ÿãƒ¬ã‚¹ãƒãƒ³ã‚¹',
                'ç„¡æ–™æ ãŒå¤§ãã„ï¼ˆ1QPSï¼‰'
            ],
            'attributes': list(self.attributes.keys()),
            'rate_limits': {
                'free': '1 query per second',
                'quota': '1,000 queries per day (default)'
            }
        }


# ãƒ†ã‚¹ãƒˆç”¨ã‚³ãƒ¼ãƒ‰
if __name__ == "__main__":
    import asyncio
    
    async def test_google_analyzer():
        """GoogleAnalyzerã®ãƒ†ã‚¹ãƒˆ"""
        print("=== Google Perspective API Analyzer Test ===")
        
        # ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼ã®åˆæœŸåŒ–
        try:
            analyzer = GoogleAnalyzer()
            print("âœ… Initialized successfully")
        except ValueError as e:
            print(f"âŒ Initialization error: {e}")
            print("Please set GOOGLE_API_KEY in .env file")
            return
        except Exception as e:
            print(f"âŒ Unexpected error: {e}")
            return
        
        # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹
        test_cases = [
            "ã“ã‚“ã«ã¡ã¯ã€è‰¯ã„å¤©æ°—ã§ã™ã­",
            "ãƒã‚«ã˜ã‚ƒãªã„ã®",
            "æ­»ã­",
            "ã‚ãªãŸã¯ã‚¯ã‚ºã ",
            "ç´ æ™´ã‚‰ã—ã„ä¸€æ—¥ã‚’ãŠéã”ã—ãã ã•ã„"
        ]
        
        print("\n--- Testing analyze_text method ---")
        for text in test_cases:
            print(f"\nãƒ†ã‚­ã‚¹ãƒˆ: '{text}'")
            result = await analyzer.analyze_text(text)
            
            if 'error' in result:
                print(f"âŒ ã‚¨ãƒ©ãƒ¼: {result['error']}")
                continue
            
            print(f"ã‚¹ã‚³ã‚¢: {result['score']:.3f}")
            print(f"æœ‰å®³åˆ¤å®š: {'ğŸš¨ æœ‰å®³' if result['is_toxic'] else 'âœ… å®‰å…¨'}")
            print(f"ä¿¡é ¼åº¦: {result['confidence']:.3f}")
            print(f"å‡¦ç†æ™‚é–“: {result['processing_time']:.3f}ç§’")
            
            if result.get('raw_scores'):
                print("å±æ€§åˆ¥ã‚¹ã‚³ã‚¢:")
                for attr, score in result['raw_scores'].items():
                    print(f"  - {attr}: {score:.3f}")
            
            if result.get('categories'):
                print("æ¤œå‡ºã‚«ãƒ†ã‚´ãƒª:")
                for cat in result['categories']:
                    print(f"  - {cat['name']}: {cat['score']:.3f}")
            
            # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’å®ˆã‚‹ãŸã‚1ç§’å¾…æ©Ÿ
            await asyncio.sleep(1)
        
        print("\n--- Testing analyze method (sync) ---")
        # åŒæœŸãƒ¡ã‚½ãƒƒãƒ‰ã®ãƒ†ã‚¹ãƒˆã¯éåŒæœŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå¤–ã§å®Ÿè¡Œ
        print("æ³¨: analyzeãƒ¡ã‚½ãƒƒãƒ‰ã®ãƒ†ã‚¹ãƒˆã¯ã€éåŒæœŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå¤–ã§å®Ÿè¡Œã—ã¦ãã ã•ã„")
        
        # ãƒ¢ãƒ‡ãƒ«æƒ…å ±
        print("\n--- Model Info ---")
        info = analyzer.get_model_info()
        print(json.dumps(info, indent=2, ensure_ascii=False))
    
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    asyncio.run(test_google_analyzer())